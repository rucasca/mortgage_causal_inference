---
title: "trabajo_final"
author: "Manuel Rubio"
date: "2024-06-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(dplyr)
library(graphics)
```


```{r}

#df <- read_csv("hmda_2017_tx_originated-records_labels.csv")
df <- read_csv("hmda_2017_wa_all-records_labels.csv")
```
## Variables relevantes

Tomaremos las variables que tengan valores útles para el estudio. Variables que solo tengan una clase (el año, por ejemplo), variables repetidas que están en texto y en numérico solo las usaremos en numérico, y variables que no aporten información bien por haber demasiadas clases, o bien no pensar que pueda haber una correlación también las quitaremos.

```{r}
resultados <- list()

# Bucle para recorrer cada columna del dataframe
for (col in colnames(df)) {
  # Contar las frecuencias de los valores en la columna
  frecuencias <- as.data.frame(table(df[[col]]))
  # Ordenar las frecuencias de forma descendente
  frecuencias <- frecuencias %>% arrange(desc(Freq))
  # Seleccionar los 10 valores más frecuentes
  top_10 <- head(frecuencias, 10)
  # Guardar los resultados en la lista
  resultados[[col]] <- top_10
}

# Mostrar los resultados

```

Nos quedamos con las variables:
- agency_name
- loan_type_name
- property_type_name
- loan_purpose_name
- owner_occupancy_name
- loan_amount_000s (numérica)
- preapproval_name
- msamd_name (probablemente haya que organizarlas, son las localizaciones)
- applicant_ethnicity_name
- co_applicant_ethnicity_name
- applicant_race_name_1
- applicant_race_name_2
- co_applicant_race_name_1 
- applicant_sex_name
- co_applicant_sex_name (aquí podemos intentar ver si a parejas del mismo sexo se les discrimina)
- applicant_income_000s (numerica)
- purchaser_type_name
- rate_spread (numerica)
- hoepa_status_name
- lien_status_name
- population (numerica)
- minority_population (numerica tambien, pero no se qué es)
- hud_median_family_income (numerica)
- tract_to_msamd_income (esto es de la riqueza de la zona creo)
- tract_to_msamd_income (ni idea de qué es esto)
- number_of_owner_occupied_units (numerica)
- number_of_1_to_4_family_units (numérica)
- action_taken_name (variable respuesta)




```{r}
columnas <- c(
  "agency_name",
  "loan_type_name",
  "property_type_name",
  "loan_purpose_name",
  "owner_occupancy_name",
  "loan_amount_000s",
  "preapproval_name",
  "msamd_name",
  "applicant_ethnicity_name",
  "co_applicant_ethnicity_name",
  "applicant_race_name_1",
  "applicant_race_name_2",
  "co_applicant_race_name_1",
  "applicant_sex_name",
  "co_applicant_sex_name",
  "applicant_income_000s",
  "purchaser_type_name",
  "rate_spread",
  "hoepa_status_name",
  "lien_status_name",
  "population",
  "minority_population",
  "hud_median_family_income",
  "tract_to_msamd_income",
  "number_of_owner_occupied_units",
  "number_of_1_to_4_family_units",
  'action_taken_name'
)
df_clean <- df %>% select(columnas)
```


```{r}
table(df_clean$loan_purpose_name)
```

```{r}
table(df_clean$action_taken_name)
```
```{r}
matriz_confusion <- table(df_clean$loan_purpose_name, df_clean$action_taken_name)

# Mostrar la matriz de confusión
print(matriz_confusion)
```

```{r}
mosaicplot(matriz_confusion, main="Matriz de Confusión: Loan Purpose vs Action Taken",
           xlab="Loan Purpose", ylab="Action Taken", color=TRUE,
           las=1, # Rotar etiquetas del eje y
           cex.axis=0.8, # Tamaño de las etiquetas
           cex.lab=0.9, # Tamaño de las etiquetas de los ejes
           border="darkgray") # Color de las líneas de los bordes

```


```{r}
library(dplyr)
library(summarytools)


# Ver las primeras filas del DataFrame
head(df_clean)

```


```{r}

# Contar el número de NA en cada columna
na_prop <- sapply(df_clean, function(x) sum(is.na(x))/dim(df_clean)[1])

# Mostrar el número de NA en cada columna
print(na_prop)

```

De entre las variables, se eliminan las tres con presencia de NAs muy alta, `rate_spread`, `msamd_name` y `applicant_race_name_2`. A continuación, de las restantes estudiaremos de forma individual las que sus NA tienen frecuencia distinta de 0.




```{r}


df_clean <- df_clean[, !names(df_clean) %in% c("msamd_name",
                                               "rate_spread", "applicant_race_name_2")]

```

Ahora se estudian las que presentan NAs.

```{r}
na_prop <- sapply(df_clean, function(x) sum(is.na(x))/dim(df_clean)[1])

na_prop <- na_prop[na_prop!=0]

# Mostrar el número de NA en cada columna
print(na_prop)


```

Salvo para la primera variable, la proporcion de NAs es infima y no merece la pena realizar la imputación de las mismas, por lo que simplemente eliminamos las instancias que presentan valores omitidos, perdiendo una cantidad de datos mínima.


Es por ello que se omiten aquellas instancias que contengan NA en todas menos en la primera variable dado que no alcanzan ni un 0.2% del total de instancias.

```{r}

vars <- c ("minority_population" ,"tract_to_msamd_income",
           "number_of_1_to_4_family_units","population","hud_median_family_income",
           "number_of_owner_occupied_units")


df_aux <- df_clean
df_aux <- df_aux[,vars]

filas_con_na <- rowSums(is.na(df_aux)) > 0

length(filas_con_na)
dim(df_aux)
dim(df_clean)
```


En cuanto a la primera, variable, estudiamos su imputación. Se tiene que la presencia de NAs para la misma puede clasificarse de la siguiente forma:

1) Missing Completely at Random (MCAR): los datos faltantes son independientes tanto de las variables observadas como de las no observadas


2) Missing at Random (MAR): los datos faltantes dependen de variables observadas pero no de las no observadas.


3) Missing Not at Random (MNAR): los datos faltantes dependen de las propias variables no observadas.

Tratamos de estudiar si la varaible en cuestion en MAR

```{r}
na_col<-is.na(df_clean$applicant_income_000s)


na_col_num <-  as.numeric(na_col)

head(na_col)

head(na_col_num)

```

```{r}
asociaciones_num <- c()
asociaciones_cat <- c()


j <- 1
k <- 1

for (i in colnames(df_clean)){
  columna <- df_clean[[i]]
  if(is.numeric(columna) && i!="applicant_income_000s"){
    
    na_col_num<-as.numeric(na_col)
    
    elems <- is.na(columna)
    na_col_num<-na_col_num[!elems]
    columna <- columna[!elems]
    
    asociaciones_num  <- c(asociaciones_num,cor(na_col_num, 
                                                columna, method = "spearman"))
    
    names(asociaciones_num)[j] <- i
    j<- j+1
    
  
    
  }
  else if(i!="applicant_income_000s"){
    na_col_fac <-  as.factor(na_col)
    
    elems <- is.na(columna)
    
    na_col_fac<-na_col_fac[!elems]
    
    columna <- columna[!elems]
    
    columna <- as.factor(columna)
    
    contingency_table <- table(na_col_fac, columna)

    print(i)

    result <- chisq.test(contingency_table)
    asociaciones_cat  <- c(asociaciones_cat,result$p.value)
    names(asociaciones_cat)[k] <- i
    k <- k + 1
    
    print(result$p.value)
    
    
    
    
  }
}


```


Se observan los resultados:

```{r}

asociaciones_num

asociaciones_cat

```

El valor de la correlación de spearman para la mayoria de valores muestra que no existe relación entre cada variable respecto a `applicant_income_000s`. En cambio, para las categoricas usando chi squared si que parece existir relación. Obaservando la ultima tabla de contingencia se tiene: 


```{r}
library(ggplot2)
df <- as.data.frame(as.table(contingency_table))

ggplot(df, aes(x = as.factor(na_col_fac), y = as.factor(columna))) +
  geom_tile(aes(fill = Freq), color = "white") +
  scale_fill_gradient(low = "blue", high = "red") +
  geom_text(aes(label = Freq), vjust = 1) +
  theme_minimal() +
  labs(title = "Contingency Table Plot",
       x = "applicant_income_000s",
       y = "number_of_1_to_4_family_units",
       fill = "Frecuencias")
```

Dado que parece que a priori `applicant_income_000s` es MAR, se hará uso de un modelo para imputar sus valores faltantes. En este caso usamos random forest.

Para ello, dividimos el conjunto de datos en instancias que contienen NA en `applicant_income_000s` y las que no. Para evaluar lo buena que ha sido la imputación, se divide el conjunto que no contiene NA en train y validación y, de tratarse de una variable con valores perdidos del tipo MAR, la imputación sera correcta.

Otra alternativa podría ser omitir la columna y tratarla como no observable, en cambio, para evitar la perdida de información se hará uso de la primera alternativa.



```{r}

test_ind <- is.na(df_clean$applicant_income_000s)
train_ind <- !test_ind


test_ind <-which(test_ind)
train_ind <- which(train_ind)

set.seed(123)

train_size <- floor(0.8 * length(train_ind))
train_indices <- sample(train_ind, size = train_size)
validation_indices <- setdiff(train_ind, train_indices)

train_indices <- sort(train_indices)

validation_indices <- sort(validation_indices)


```




```{r}
library(randomForest)


train <- df_clean[train_ind,]

model <- randomForest(applicant_income_000s ~ ., 
                      data = train, importance = TRUE, ntree = 100)


sum(is.na(train$applicant_income_000s))

```





```{r}
correlation <- apply(df_clean, 2, function(x) cor(na_col, x, method = "spearman"))


```



```{r}

# Ver el resumen estadístico de todas las variables
summary(df)
```


```{r}
head(df$applicant_ethnicity_name)

head(df$applicant_ethnicity)
```


