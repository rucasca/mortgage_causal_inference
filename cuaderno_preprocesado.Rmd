---
title: "trabajo_final"
author: "Manuel Rubio"
date: "2024-06-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(dplyr)
library(graphics)
```


```{r}

#df <- read_csv("hmda_2017_tx_originated-records_labels.csv")
df <- read_csv("hmda_2017_wa_all-records_labels.csv")
```
## Variables relevantes

Tomaremos las variables que tengan valores útles para el estudio. Variables que solo tengan una clase (el año, por ejemplo), variables repetidas que están en texto y en numérico solo las usaremos en numérico, y variables que no aporten información bien por haber demasiadas clases, o bien no pensar que pueda haber una correlación también las quitaremos.

```{r}
resultados <- list()

# Bucle para recorrer cada columna del dataframe
for (col in colnames(df)) {
  # Contar las frecuencias de los valores en la columna
  frecuencias <- as.data.frame(table(df[[col]]))
  # Ordenar las frecuencias de forma descendente
  frecuencias <- frecuencias %>% arrange(desc(Freq))
  # Seleccionar los 10 valores más frecuentes
  top_10 <- head(frecuencias, 10)
  # Guardar los resultados en la lista
  resultados[[col]] <- top_10
}

# Mostrar los resultados

```

Nos quedamos con las variables:
- agency_name
- loan_type_name
- property_type_name
- loan_purpose_name
- owner_occupancy_name
- loan_amount_000s (numérica)
- preapproval_name
- msamd_name (probablemente haya que organizarlas, son las localizaciones)
- applicant_ethnicity_name
- co_applicant_ethnicity_name
- applicant_race_name_1
- applicant_race_name_2
- co_applicant_race_name_1 
- applicant_sex_name
- co_applicant_sex_name (aquí podemos intentar ver si a parejas del mismo sexo se les discrimina)
- applicant_income_000s (numerica)
- purchaser_type_name
- rate_spread (numerica)
- hoepa_status_name
- lien_status_name
- population (numerica)
- minority_population (numerica tambien, pero no se qué es)
- hud_median_family_income (numerica)
- tract_to_msamd_income (esto es de la riqueza de la zona creo)
- tract_to_msamd_income (ni idea de qué es esto)
- number_of_owner_occupied_units (numerica)
- number_of_1_to_4_family_units (numérica)
- action_taken_name (variable respuesta)




```{r}
columnas <- c(
  "agency_name",
  "loan_type_name",
  "property_type_name",
  "loan_purpose_name",
  "owner_occupancy_name",
  "loan_amount_000s",
  "preapproval_name",
  "msamd_name",
  "applicant_ethnicity_name",
  "co_applicant_ethnicity_name",
  "applicant_race_name_1",
  "applicant_race_name_2",
  "co_applicant_race_name_1",
  "applicant_sex_name",
  "co_applicant_sex_name",
  "applicant_income_000s",
  "purchaser_type_name",
  "rate_spread",
  "hoepa_status_name",
  "lien_status_name",
  "population",
  "minority_population",
  "hud_median_family_income",
  "tract_to_msamd_income",
  "number_of_owner_occupied_units",
  "number_of_1_to_4_family_units",
  'action_taken_name'
)
df_clean <- df %>% select(columnas)
```


```{r}
table(df_clean$loan_purpose_name)
```

```{r}
table(df_clean$action_taken_name)
```
```{r}
matriz_confusion <- table(df_clean$loan_purpose_name, df_clean$action_taken_name)

# Mostrar la matriz de confusión
print(matriz_confusion)
```

```{r}
mosaicplot(matriz_confusion, main="Matriz de Confusión: Loan Purpose vs Action Taken",
           xlab="Loan Purpose", ylab="Action Taken", color=TRUE,
           las=1, # Rotar etiquetas del eje y
           cex.axis=0.8, # Tamaño de las etiquetas
           cex.lab=0.9, # Tamaño de las etiquetas de los ejes
           border="darkgray") # Color de las líneas de los bordes

```


```{r}
library(dplyr)
library(summarytools)


# Ver las primeras filas del DataFrame
head(df_clean)

```


```{r}

# Contar el número de NA en cada columna
na_prop <- sapply(df_clean, function(x) sum(is.na(x))/dim(df_clean)[1])

# Mostrar el número de NA en cada columna
print(na_prop)

```

De entre las variables, se eliminan las tres con presencia de NAs muy alta, `rate_spread`, `msamd_name` y `applicant_race_name_2`. A continuación, de las restantes estudiaremos de forma individual las que sus NA tienen frecuencia distinta de 0.




```{r}


df_clean <- df_clean[, !names(df_clean) %in% c("msamd_name",
                                               "rate_spread", "applicant_race_name_2")]

```

Ahora se estudian las que presentan NAs.

```{r}
na_prop <- sapply(df_clean, function(x) sum(is.na(x))/dim(df_clean)[1])

na_prop <- na_prop[na_prop!=0]

# Mostrar el número de NA en cada columna
print(na_prop)


```

Salvo para la primera variable, la proporcion de NAs es infima y no merece la pena realizar la imputación de las mismas, por lo que simplemente eliminamos las instancias que presentan valores omitidos, perdiendo una cantidad de datos mínima.


Es por ello que se omiten aquellas instancias que contengan NA en todas menos en la primera variable dado que no alcanzan ni un 0.2% del total de instancias.

```{r}

vars <- c ("minority_population" ,"tract_to_msamd_income",
           "number_of_1_to_4_family_units","population","hud_median_family_income",
           "number_of_owner_occupied_units")


df_aux <- df_clean
df_aux <- df_aux[,vars]

filas_con_na <- rowSums(is.na(df_aux)) > 0

df_aux <- df_aux[!filas_con_na,]

dim(df_aux)

dim(df_clean)

df_clean <- df_clean[!filas_con_na,]


```


En cuanto a la primera, variable, estudiamos su imputación. Se tiene que la presencia de NAs para la misma puede clasificarse de la siguiente forma:

1) Missing Completely at Random (MCAR): los datos faltantes son independientes tanto de las variables observadas como de las no observadas


2) Missing at Random (MAR): los datos faltantes dependen de variables observadas pero no de las no observadas.


3) Missing Not at Random (MNAR): los datos faltantes dependen de las propias variables no observadas.

Tratamos de estudiar si la varaible en cuestion en MAR

```{r}


na_col<-is.na(df_clean$applicant_income_000s)

na_col_num <-  as.numeric(na_col)

head(na_col)

head(na_col_num)

```

```{r}
asociaciones_num <- c()
asociaciones_cat <- c()


j <- 1
k <- 1

for (i in colnames(df_clean)){
  columna <- df_clean[[i]]
  if(is.numeric(columna) && i!="applicant_income_000s"){
    
    na_col_num<-as.numeric(na_col)
    
    elems <- is.na(columna)
    na_col_num<-na_col_num[!elems]
    columna <- columna[!elems]
    
    asociaciones_num  <- c(asociaciones_num,cor(na_col_num, 
                                                columna, method = "spearman"))
    
    names(asociaciones_num)[j] <- i
    j<- j+1
    
  
    
  }
  else if(i!="applicant_income_000s"){
    na_col_fac <-  as.factor(na_col)
    
    elems <- is.na(columna)
    
    na_col_fac<-na_col_fac[!elems]
    
    columna <- columna[!elems]
    
    columna <- as.factor(columna)
    
    contingency_table <- table(na_col_fac, columna)

    print(i)

    result <- chisq.test(contingency_table)
    asociaciones_cat  <- c(asociaciones_cat,result$p.value)
    names(asociaciones_cat)[k] <- i
    k <- k + 1
    
    print(result$p.value)
    
    
    
    
  }
}


```


Se observan los resultados:

```{r}

asociaciones_num

asociaciones_cat

```

El valor de la correlación de spearman para la mayoria de valores muestra que no existe relación entre cada variable respecto a `applicant_income_000s`. En cambio, para las categoricas usando chi squared si que parece existir relación. Obaservando la ultima tabla de contingencia se tiene: 




```{r}

library(ggplot2)
row_sums <- apply(contingency_table, 1, sum)

# Normaliza los datos dividiendo cada valor por la suma de la fila
normalized_table <- contingency_table / row_sums

# Convierte la tabla normalizada en un data frame
df <- as.data.frame(as.table(normalized_table))

# Gráfico de barras
ggplot(df, aes(x = as.factor(na_col_fac), y = as.factor(columna))) +
  geom_tile(aes(fill = Freq), color = "white") +
  scale_fill_gradient(low = "blue", high = "red") +
  geom_text(aes(label = round(Freq, 2)), vjust = 1) + # Añade la etiqueta de frecuencia
  theme_minimal() +
  labs(title = "Contingency Table Plot",
       x = "applicant_income_000s",
       y = "number_of_1_to_4_family_units",
       fill = "Frecuencias")
```


Dado que parece que a priori `applicant_income_000s` es MAR, se hará uso de un modelo para imputar sus valores faltantes. En este caso usamos random forest.

Para ello, dividimos el conjunto de datos en instancias que contienen NA en `applicant_income_000s` y las que no. Para evaluar lo buena que ha sido la imputación, se divide el conjunto que no contiene NA en train y validación y, de tratarse de una variable con valores perdidos del tipo MAR, la imputación sera correcta.

Otra alternativa podría ser omitir la columna y tratarla como no observable, en cambio, para evitar la perdida de información se hará uso de la primera alternativa.



```{r}

test_ind <- is.na(df_clean$applicant_income_000s)
train_ind <- !test_ind


test_ind <-which(test_ind)
train_ind <- which(train_ind)

set.seed(123)

train_size <- floor(0.1 * length(train_ind))
train_indices <- sample(train_ind, size = train_size)
validation_indices <- setdiff(train_ind, train_indices)

train_indices <- sort(train_indices)

validation_indices <- sort(validation_indices)


```

Una vez particionado el conjunto, se entrena el modelo con los datos: 


```{r}
library(randomForest)


train <- df_clean[train_indices,]

dim(train)

model <- randomForest(as.numeric(applicant_income_000s) ~ ., 
                      data = train, importance = TRUE, ntree = 30)


validation <- df_clean[validation_indices,]
predictions <- predict(model, validation)

```




Una vez entrenado se realiza la predicción del conjunto de validación para estudiar lo buenas que son las predicciones sobre datos etiquetados:

```{r}
head(model$predicted)

head(train$applicant_income_000s)

```


Además, se realiza una exploración de las variables de importancia de nuestro modelo:

```{r}

```


Una vez evaluados los resultados, se realiza la imputación de los NA usando el modelo:

```{r}

```





### 

Una vez obtenido el conjunto de datos preporcesado sin NAs, se lleva a cabo una selección mediante matching para tratar de estimar lo siguiente:


1) Estimar el impacto del propósito de la hipoteca (loan purpose = "Refinancing") sobre rechazo de la misma (Action taken: denied)

2) Estimar el efecto de __otras variables__



Comenzamos con la estimación del impacto del proposito de la hipoteca

```{r}
library(tidyverse)
library(MatchIt)
library(cobalt)

```

```{r}
head(df_clean$loan_purpose_name)
```


```{r}
head(df_clean$action_taken_name)
```
Se transforman en columnas binarias, donde se coloca un 0 en el caso de un proposito distinto al de "Refinancing" y un 1 en el caso contrario. De la misma manera se imputa un 1 en el caso de ser denegada y un 0 en el caso contrario.


```{r}

df <- df_clean

df <- na.omit(df)

```



```{r}
refinanzing <- df$loan_purpose_name == "Refinancing"
refinanzing <- as.numeric(refinanzing)

denied <- df$action_taken_name =="Loan originated"
denied <- as.numeric(denied)
```


```{r}

df <- subset(df, select = -c(loan_purpose_name,action_taken_name))

df$D <- as.factor(refinanzing)

df$y <- denied

head(df)

```

En primer lugar, se evalua la diferencia de medias agrupando por el tratamiento aplicado, para asi obtener el estimador sesgado por diferencia de medias:

```{r}
library(dplyr)

# Agrupar por la columna 'grupo' y calcular la media de 'valor'
medias_por_grupo <- df %>%
  group_by(D) %>%
  summarise(media_valor = mean(y))

# Ver las medias por grupo
print(medias_por_grupo)
```



Este estimador sesgado revela que existen diferencias de medias entre los dos grupos. Dado que la condición de independencia no ha de cumplirse, necesitamos aplicar otros métodos en este caso para estudiar el efecto del tratamiento.

Además, se puede comprobar con figuras como las siguientes que el emparejamiento de variables no sigue la misma distribución: 

```{r}


ggplot(df, aes(x = loan_amount_000s,fill = D)) + 
          geom_density(alpha=0.5)+scale_y_continuous(limits=c(0,0.2))+
          scale_x_continuous(limits=c(0,50))


```


Es por ello que aplicaremos matchit como preprocesamiento y, en base a un supuesto de independencia condicional, estudiaremos el efecto causal de D sobre Y dado X, donde X son el resto de variables observadas.

```{r}

df_aux <-  df
for (col in colnames(df)) {
  if (is.character(df[[col]])) {
    df_aux[[col]] <- as.factor(df_aux[[col]])
  }
}

head(df_aux)

df <- df_aux
```

```{r}
colnames(df)
```
```{r}

set.seed(123)

# Split the train indices into training and validation sets
train_size <- floor(0.01 * length(train_ind))
train_indices <- sample(train_ind, size = train_size)

df_aux <- df[train_indices,]

dim(df_aux)


df_aux <- drop_na(df_aux)
```


```{r}

library(MatchIt)
m.ps.nn.1 <- matchit(y ~ agency_name +
            property_type_name + loan_amount_000s + 
            applicant_ethnicity_name + applicant_race_name_1 + 
              applicant_sex_name +applicant_income_000s +hoepa_status_name +population ,
                  method="nearest",
                  distance="cbps",
                  data=df_aux) 


m.ps.nn.1
```

```{r}
love.plot(m.ps.nn.1,stats = c("m","var","ks"), 
          abs = TRUE,thresholds=c(m=0.1,ks=0.05,var=2),
          stars = "std")
```


```{r}
m.ps.nn.2 <- matchit(y ~ agency_name +
            property_type_name + loan_amount_000s + 
            applicant_ethnicity_name + applicant_race_name_1 + 
              applicant_sex_name +applicant_income_000s +hoepa_status_name +population ,
                  method="nearest",
                  distance="mahalanobis",
                  data=df_aux,
            replace = TRUE) 


m.ps.nn.2
```
```{r}


love.plot(m.ps.nn.2,stats = c("m","var","ks"), 
          abs = TRUE,thresholds=c(m=0.1,ks=0.05,var=2),
          stars = "std")


```


```{r}

library(ggplot2)
library(reshape2)
library(corrplot)

# Suponiendo que tu dataframe se llama 'df'
# Calcula la matriz de correlación
cor_matrix <- cor(df[,sapply(df, is.numeric)], use = "complete.obs")

# Convierte la matriz de correlación en un formato largo para ggplot2
cor_data <- melt(cor_matrix)

corrplot(cor_matrix, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45)

```

